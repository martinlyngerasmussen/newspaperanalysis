{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook will demonstrate how to conduct LDA analysis. The code was written by Andres Azqueta and edited by Martin Lynge Rasmussen.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Install the required packages\n",
    "2. Load and format the text files\n",
    "3. Carry out LDA analysis\n",
    "\n",
    "\n",
    "Before proceding, you should: \n",
    "1. Create a folder called \"data\" with two subfolders called \"input\" and \"output\". \n",
    "2. Before you proceed, you need to save all of the newspaper articles you have downloaded to the \"input\" folder. \n",
    "3. You need to name the files as Chinese_Risk_%d.json, where %d is a number, i.e. name the first document as 1. You can use other names, but in such case remember to change the names in the remainder of this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in c:\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in c:\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in c:\\anaconda3\\lib\\site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: Cython==0.29.14 in c:\\anaconda3\\lib\\site-packages (from gensim) (0.29.14)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in c:\\anaconda3\\lib\\site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in c:\\anaconda3\\lib\\site-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyLDAvis in c:\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.17.0)\n",
      "Requirement already satisfied: future in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.24.2)\n",
      "Requirement already satisfied: pytest in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.16.2)\n",
      "Requirement already satisfied: funcy in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.15)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.1)\n",
      "Requirement already satisfied: numexpr in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.6.9)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.33.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (40.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (19.1.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: pluggy>=0.7 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.9.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Libraries to download\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "%pip install -U gensim\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "%pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and format the textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "os.chdir('C:/Users/rasmusa/Desktop/python/Chinese_Risk/data/output') # Change this\n",
    "## Tokenizing\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "#en_stop = stopwords.words('english')\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "## Reading the data\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import pandas\n",
    "\n",
    "appended_data = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df0 = pandas.DataFrame([json.loads(l) for l in open('Chinese_Risk_%d.json' % i)])\n",
    "    appended_data.append(df0)\n",
    "    \n",
    "appended_data = pandas.concat(appended_data)\n",
    "doc_set = appended_data.body\n",
    "print(len(doc_set))\n",
    "\n",
    "\n",
    "## English Stopwords\n",
    "English_Stopwords = open(\"English_Stopwords.txt\").read() # also contain uni-characters\n",
    "English_Stopwords1=English_Stopwords.split('\\n')\n",
    "\n",
    "\n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    \n",
    "    \n",
    "    # remove all tokens that are not alphabetic\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    #stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    stopped_tokens = [i for i in words if not i in English_Stopwords1]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "#The function doc2bow() simply counts the number of occurrences of each distinct word, \n",
    "#converts the word to its integer word id and returns the result as a sparse vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LDA analysis\n",
    "You can change the number of topics if you wish. The output shows all of the identified topics. We will later show how to explore the topics in a more visually-appealing manner.\n",
    "\n",
    "The below shows an example of topic 0. Each topic is separated by parenthesis. And the weights show the weight of the given word in the topic. \n",
    "\n",
    "[(0, '0.029*\"ma\" + 0.020*\"alibaba\" + 0.012*\"yuan\" + 0.012*\"dollar\" + 0.010*\"china\" + 0.009*\"compani\" + 0.009*\"chines\" + 0.008*\"alipay\" + 0.008*\"financi\" + 0.007*\"intern\" + 0.007*\"asset\" + 0.006*\"investor\" + 0.006*\"even\" + 0.006*\"global\" + 0.005*\"currenc\" + 0.005*\"would\" + 0.005*\"first\" + 0.004*\"execut\" + 0.004*\"trillion\" + 0.004*\"jack\" + 0.004*\"america\" + 0.004*\"prasad\" + 0.004*\"commerc\" + 0.004*\"bank\" + 0.004*\"system\" + 0.004*\"trade\" + 0.004*\"busi\" + 0.003*\"market\" + 0.003*\"among\" + 0.003*\"chairman\"')\n",
    "\n",
    "### 3.1. Initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.029*\"ma\" + 0.020*\"alibaba\" + 0.012*\"yuan\" + 0.012*\"dollar\" + 0.010*\"china\" + 0.009*\"compani\" + 0.009*\"chines\" + 0.008*\"alipay\" + 0.008*\"financi\" + 0.007*\"intern\" + 0.007*\"asset\" + 0.006*\"investor\" + 0.006*\"even\" + 0.006*\"global\" + 0.005*\"currenc\" + 0.005*\"would\" + 0.005*\"first\" + 0.004*\"execut\" + 0.004*\"trillion\" + 0.004*\"jack\" + 0.004*\"america\" + 0.004*\"prasad\" + 0.004*\"commerc\" + 0.004*\"bank\" + 0.004*\"system\" + 0.004*\"trade\" + 0.004*\"busi\" + 0.003*\"market\" + 0.003*\"among\" + 0.003*\"chairman\"'), (1, '0.044*\"bank\" + 0.017*\"china\" + 0.013*\"loan\" + 0.011*\"financi\" + 0.011*\"year\" + 0.010*\"risk\" + 0.009*\"credit\" + 0.009*\"per\" + 0.009*\"cent\" + 0.008*\"financ\" + 0.008*\"lend\" + 0.007*\"yuan\" + 0.007*\"product\" + 0.006*\"compani\" + 0.006*\"fund\" + 0.006*\"billion\" + 0.006*\"sector\" + 0.005*\"debt\" + 0.005*\"market\" + 0.005*\"shadow\" + 0.005*\"mainland\" + 0.005*\"growth\" + 0.005*\"system\" + 0.005*\"regul\" + 0.005*\"new\" + 0.005*\"last\" + 0.004*\"manag\" + 0.004*\"govern\" + 0.004*\"trust\" + 0.004*\"would\"'), (2, '0.024*\"bond\" + 0.023*\"market\" + 0.019*\"china\" + 0.017*\"investor\" + 0.015*\"year\" + 0.013*\"debt\" + 0.012*\"stock\" + 0.012*\"rate\" + 0.011*\"chines\" + 0.010*\"compani\" + 0.009*\"bank\" + 0.009*\"govern\" + 0.007*\"yield\" + 0.007*\"fund\" + 0.006*\"borrow\" + 0.006*\"invest\" + 0.006*\"buy\" + 0.006*\"manag\" + 0.005*\"firm\" + 0.005*\"billion\" + 0.005*\"yuan\" + 0.004*\"financi\" + 0.004*\"share\" + 0.004*\"accord\" + 0.004*\"shanghai\" + 0.004*\"asset\" + 0.004*\"month\" + 0.004*\"interest\" + 0.004*\"last\" + 0.004*\"beij\"'), (3, '0.031*\"china\" + 0.014*\"chines\" + 0.009*\"countri\" + 0.009*\"develop\" + 0.008*\"world\" + 0.007*\"new\" + 0.007*\"region\" + 0.007*\"intern\" + 0.006*\"infrastructur\" + 0.005*\"asia\" + 0.005*\"foreign\" + 0.005*\"institut\" + 0.005*\"one\" + 0.005*\"macau\" + 0.005*\"invest\" + 0.005*\"nation\" + 0.004*\"asian\" + 0.004*\"secur\" + 0.004*\"govern\" + 0.004*\"power\" + 0.004*\"xi\" + 0.004*\"militari\" + 0.004*\"pacif\" + 0.004*\"polit\" + 0.004*\"say\" + 0.004*\"sub\" + 0.004*\"beij\" + 0.004*\"bank\" + 0.004*\"econom\" + 0.004*\"offici\"'), (4, '0.012*\"year\" + 0.011*\"market\" + 0.009*\"price\" + 0.008*\"investor\" + 0.007*\"stock\" + 0.007*\"oil\" + 0.006*\"trade\" + 0.006*\"bond\" + 0.006*\"china\" + 0.006*\"greec\" + 0.006*\"dollar\" + 0.006*\"global\" + 0.006*\"index\" + 0.006*\"bank\" + 0.006*\"month\" + 0.005*\"data\" + 0.005*\"currenc\" + 0.005*\"expect\" + 0.005*\"sale\" + 0.005*\"fell\" + 0.005*\"treasuri\" + 0.004*\"rose\" + 0.004*\"rate\" + 0.004*\"week\" + 0.004*\"econom\" + 0.004*\"new\" + 0.004*\"billion\" + 0.004*\"may\" + 0.004*\"report\" + 0.004*\"reserv\"'), (5, '0.035*\"yuan\" + 0.024*\"china\" + 0.024*\"currenc\" + 0.018*\"chines\" + 0.011*\"dollar\" + 0.010*\"year\" + 0.007*\"market\" + 0.007*\"would\" + 0.007*\"trade\" + 0.006*\"beij\" + 0.006*\"renminbi\" + 0.006*\"foreign\" + 0.006*\"investor\" + 0.006*\"bank\" + 0.005*\"also\" + 0.005*\"london\" + 0.005*\"financi\" + 0.005*\"billion\" + 0.004*\"exchang\" + 0.004*\"citi\" + 0.004*\"global\" + 0.004*\"still\" + 0.004*\"reserv\" + 0.004*\"intern\" + 0.004*\"project\" + 0.004*\"countri\" + 0.003*\"month\" + 0.003*\"use\" + 0.003*\"imf\" + 0.003*\"time\"'), (6, '0.020*\"properti\" + 0.018*\"invest\" + 0.017*\"develop\" + 0.017*\"chines\" + 0.013*\"estat\" + 0.013*\"year\" + 0.012*\"real\" + 0.011*\"china\" + 0.010*\"citi\" + 0.007*\"project\" + 0.007*\"home\" + 0.006*\"million\" + 0.006*\"buyer\" + 0.006*\"new\" + 0.006*\"group\" + 0.006*\"market\" + 0.006*\"also\" + 0.006*\"financi\" + 0.006*\"manag\" + 0.005*\"hous\" + 0.005*\"one\" + 0.005*\"oversea\" + 0.005*\"japan\" + 0.005*\"price\" + 0.005*\"compani\" + 0.005*\"build\" + 0.005*\"buy\" + 0.005*\"australia\" + 0.005*\"busi\" + 0.005*\"look\"'), (7, '0.020*\"copper\" + 0.019*\"china\" + 0.018*\"bond\" + 0.016*\"price\" + 0.015*\"year\" + 0.010*\"metal\" + 0.010*\"import\" + 0.008*\"yield\" + 0.008*\"commod\" + 0.008*\"iron\" + 0.007*\"market\" + 0.007*\"ore\" + 0.006*\"yuan\" + 0.006*\"demand\" + 0.006*\"use\" + 0.006*\"investor\" + 0.006*\"invest\" + 0.006*\"sinc\" + 0.006*\"compani\" + 0.005*\"rate\" + 0.005*\"mani\" + 0.005*\"economi\" + 0.005*\"high\" + 0.005*\"fall\" + 0.005*\"month\" + 0.005*\"growth\" + 0.005*\"return\" + 0.004*\"billion\" + 0.004*\"trader\" + 0.004*\"chines\"'), (8, '0.018*\"rate\" + 0.018*\"china\" + 0.016*\"deposit\" + 0.009*\"chines\" + 0.009*\"bank\" + 0.008*\"insur\" + 0.008*\"market\" + 0.008*\"could\" + 0.008*\"would\" + 0.006*\"year\" + 0.006*\"beij\" + 0.006*\"aircraft\" + 0.006*\"leas\" + 0.006*\"interest\" + 0.005*\"debt\" + 0.005*\"one\" + 0.005*\"higher\" + 0.004*\"economi\" + 0.004*\"new\" + 0.004*\"airlin\" + 0.004*\"econom\" + 0.004*\"growth\" + 0.004*\"state\" + 0.004*\"financi\" + 0.004*\"countri\" + 0.004*\"borrow\" + 0.004*\"govern\" + 0.004*\"term\" + 0.004*\"deal\" + 0.004*\"trade\"'), (9, '0.031*\"china\" + 0.014*\"chines\" + 0.012*\"russia\" + 0.011*\"project\" + 0.011*\"africa\" + 0.010*\"ga\" + 0.009*\"beij\" + 0.008*\"billion\" + 0.008*\"sanction\" + 0.007*\"year\" + 0.007*\"south\" + 0.007*\"countri\" + 0.007*\"russian\" + 0.006*\"oil\" + 0.006*\"deal\" + 0.006*\"energi\" + 0.006*\"total\" + 0.005*\"economi\" + 0.005*\"invest\" + 0.005*\"xi\" + 0.005*\"presid\" + 0.005*\"state\" + 0.005*\"western\" + 0.005*\"two\" + 0.005*\"econom\" + 0.005*\"financ\" + 0.004*\"last\" + 0.004*\"natur\" + 0.004*\"partner\" + 0.004*\"trade\"'), (10, '0.022*\"china\" + 0.014*\"market\" + 0.012*\"compani\" + 0.011*\"chines\" + 0.010*\"stock\" + 0.010*\"list\" + 0.008*\"investor\" + 0.008*\"share\" + 0.008*\"year\" + 0.006*\"invest\" + 0.005*\"offer\" + 0.005*\"fund\" + 0.005*\"chang\" + 0.005*\"startup\" + 0.005*\"public\" + 0.005*\"hong\" + 0.005*\"kong\" + 0.004*\"ventur\" + 0.004*\"busi\" + 0.004*\"one\" + 0.004*\"capit\" + 0.004*\"technolog\" + 0.003*\"big\" + 0.003*\"beij\" + 0.003*\"peopl\" + 0.003*\"million\" + 0.003*\"firm\" + 0.003*\"citi\" + 0.003*\"shanghai\" + 0.003*\"climat\"'), (11, '0.031*\"growth\" + 0.030*\"economi\" + 0.020*\"china\" + 0.017*\"econom\" + 0.013*\"global\" + 0.012*\"polici\" + 0.010*\"year\" + 0.010*\"market\" + 0.009*\"rate\" + 0.009*\"offici\" + 0.009*\"world\" + 0.007*\"countri\" + 0.007*\"currenc\" + 0.007*\"central\" + 0.007*\"financ\" + 0.006*\"beij\" + 0.006*\"financi\" + 0.006*\"reform\" + 0.005*\"export\" + 0.005*\"also\" + 0.005*\"meet\" + 0.005*\"imf\" + 0.005*\"could\" + 0.005*\"bank\" + 0.005*\"expect\" + 0.005*\"risk\" + 0.005*\"devalu\" + 0.004*\"would\" + 0.004*\"economist\" + 0.004*\"spend\"'), (12, '0.029*\"bank\" + 0.027*\"china\" + 0.013*\"govern\" + 0.013*\"central\" + 0.011*\"offici\" + 0.010*\"chines\" + 0.010*\"year\" + 0.008*\"market\" + 0.007*\"rate\" + 0.006*\"yuan\" + 0.006*\"fund\" + 0.006*\"beij\" + 0.006*\"compani\" + 0.006*\"state\" + 0.006*\"growth\" + 0.005*\"pboc\" + 0.005*\"would\" + 0.005*\"economi\" + 0.005*\"financi\" + 0.005*\"invest\" + 0.005*\"move\" + 0.005*\"debt\" + 0.005*\"accord\" + 0.005*\"economist\" + 0.005*\"peopl\" + 0.005*\"financ\" + 0.005*\"econom\" + 0.005*\"one\" + 0.005*\"countri\" + 0.005*\"plan\"'), (13, '0.015*\"bank\" + 0.011*\"chines\" + 0.009*\"china\" + 0.008*\"loan\" + 0.008*\"commod\" + 0.008*\"year\" + 0.007*\"qingdao\" + 0.006*\"compani\" + 0.006*\"port\" + 0.006*\"oil\" + 0.005*\"million\" + 0.005*\"metal\" + 0.005*\"resourc\" + 0.005*\"price\" + 0.005*\"foreign\" + 0.005*\"back\" + 0.005*\"billion\" + 0.004*\"accord\" + 0.004*\"standard\" + 0.004*\"western\" + 0.004*\"trade\" + 0.004*\"deal\" + 0.004*\"mine\" + 0.004*\"latin\" + 0.004*\"collater\" + 0.004*\"use\" + 0.004*\"chen\" + 0.004*\"state\" + 0.004*\"also\" + 0.004*\"lender\"'), (14, '0.036*\"market\" + 0.020*\"stock\" + 0.015*\"china\" + 0.013*\"margin\" + 0.013*\"investor\" + 0.009*\"per\" + 0.009*\"cent\" + 0.008*\"risk\" + 0.008*\"invest\" + 0.007*\"chines\" + 0.007*\"trade\" + 0.007*\"financ\" + 0.007*\"secur\" + 0.006*\"year\" + 0.006*\"share\" + 0.006*\"financi\" + 0.006*\"yuan\" + 0.005*\"growth\" + 0.005*\"shanghai\" + 0.005*\"economi\" + 0.005*\"bank\" + 0.005*\"analyst\" + 0.005*\"trillion\" + 0.004*\"may\" + 0.004*\"leverag\" + 0.004*\"reform\" + 0.004*\"firm\" + 0.004*\"would\" + 0.004*\"index\" + 0.004*\"brokerag\"'), (15, '0.025*\"kong\" + 0.025*\"hong\" + 0.016*\"china\" + 0.012*\"compani\" + 0.010*\"chines\" + 0.008*\"year\" + 0.008*\"busi\" + 0.006*\"beij\" + 0.006*\"citi\" + 0.006*\"technolog\" + 0.006*\"execut\" + 0.006*\"financi\" + 0.005*\"million\" + 0.005*\"govern\" + 0.005*\"servic\" + 0.005*\"industri\" + 0.004*\"smartphon\" + 0.004*\"internet\" + 0.004*\"use\" + 0.004*\"rule\" + 0.004*\"mainland\" + 0.004*\"billion\" + 0.004*\"project\" + 0.004*\"oper\" + 0.004*\"protest\" + 0.004*\"invest\" + 0.004*\"state\" + 0.003*\"onlin\" + 0.003*\"market\" + 0.003*\"also\"'), (16, '0.012*\"year\" + 0.012*\"price\" + 0.011*\"market\" + 0.008*\"china\" + 0.006*\"like\" + 0.006*\"may\" + 0.006*\"time\" + 0.006*\"compani\" + 0.006*\"growth\" + 0.005*\"investor\" + 0.005*\"could\" + 0.005*\"would\" + 0.005*\"oil\" + 0.005*\"bank\" + 0.005*\"chines\" + 0.005*\"emerg\" + 0.004*\"even\" + 0.004*\"risk\" + 0.004*\"also\" + 0.004*\"billion\" + 0.004*\"countri\" + 0.004*\"trade\" + 0.004*\"rise\" + 0.003*\"quarter\" + 0.003*\"make\" + 0.003*\"earn\" + 0.003*\"invest\" + 0.003*\"last\" + 0.003*\"share\" + 0.003*\"valu\"'), (17, '0.020*\"china\" + 0.016*\"compani\" + 0.014*\"movi\" + 0.012*\"film\" + 0.012*\"chines\" + 0.011*\"studio\" + 0.011*\"invest\" + 0.009*\"million\" + 0.009*\"deal\" + 0.008*\"product\" + 0.007*\"year\" + 0.006*\"entertain\" + 0.006*\"hollywood\" + 0.005*\"market\" + 0.005*\"billion\" + 0.005*\"execut\" + 0.005*\"releas\" + 0.005*\"look\" + 0.005*\"co\" + 0.005*\"ga\" + 0.004*\"box\" + 0.004*\"pictur\" + 0.004*\"one\" + 0.004*\"new\" + 0.004*\"group\" + 0.004*\"money\" + 0.004*\"also\" + 0.004*\"soni\" + 0.004*\"time\" + 0.004*\"back\"'), (18, '0.021*\"china\" + 0.018*\"market\" + 0.015*\"trade\" + 0.013*\"chines\" + 0.011*\"investor\" + 0.011*\"year\" + 0.009*\"stock\" + 0.007*\"yuan\" + 0.007*\"futur\" + 0.007*\"exchang\" + 0.007*\"index\" + 0.006*\"shanghai\" + 0.006*\"foreign\" + 0.006*\"compani\" + 0.006*\"price\" + 0.006*\"financi\" + 0.005*\"wednesday\" + 0.005*\"currenc\" + 0.005*\"billion\" + 0.005*\"month\" + 0.005*\"sinc\" + 0.005*\"last\" + 0.004*\"could\" + 0.004*\"share\" + 0.004*\"week\" + 0.004*\"manag\" + 0.004*\"one\" + 0.004*\"bank\" + 0.004*\"money\" + 0.004*\"bitcoin\"'), (19, '0.037*\"compani\" + 0.024*\"chines\" + 0.017*\"alibaba\" + 0.016*\"billion\" + 0.013*\"china\" + 0.013*\"list\" + 0.012*\"investor\" + 0.011*\"firm\" + 0.011*\"market\" + 0.011*\"share\" + 0.009*\"deal\" + 0.009*\"privat\" + 0.009*\"offer\" + 0.008*\"year\" + 0.007*\"million\" + 0.007*\"group\" + 0.006*\"chaori\" + 0.006*\"take\" + 0.005*\"inc\" + 0.005*\"technolog\" + 0.005*\"new\" + 0.005*\"stock\" + 0.005*\"public\" + 0.005*\"solar\" + 0.005*\"could\" + 0.005*\"sharehold\" + 0.004*\"ipo\" + 0.004*\"valuat\" + 0.004*\"co\" + 0.004*\"invest\"')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n",
      "C:\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "# generate LDA model, need to set minimum probability to zero otherwise topics will be surpresed in the next steps\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=20, id2word = dictionary, passes=50, minimum_probability=0)\n",
    "ldamodel.save(\"model.ldaFinanceRisk20\") \n",
    "#class gensim.models.ldamodel.LdaModel(corpus=None, num_topics=100, id2word=None, distributed=False, \n",
    "#chunksize=2000, passes=1, update_every=1, alpha='symmetric', eta=None, decay=0.5, offset=1.0, eval_every=10, \n",
    "#iterations=50, gamma_threshold=0.001, minimum_probability=0.01)\n",
    "#passes: optional. The number of laps the model will take through corpus. \n",
    "#The greater the number of passes, the more accurate the model will be. A lot of passes can be slow on a very large corpus.\n",
    "\n",
    "print(ldamodel.print_topics(num_topics=20, num_words=30))\n",
    "\n",
    "## visualization of the topics\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "\n",
    "vis_data = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "pyLDAvis.save_html(vis_data, 'Chinse_Financial_Risk_Topics_20.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Save the topics in a readable csv file\n",
    "The below saves the top 20 topics; you can change this to another number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## -----------------------------------------------------------------------------------------------------------##\n",
    "# ------------------------------------- OBTAINING ARTICLES-TOPICS DISTRIBUTIONS -------------------------------#\n",
    "## -----------------------------------------------------------------------------------------------------------##\n",
    "\n",
    "# https://web.stanford.edu/class/stats202/content/lab18.htm very complete link with LDA information\n",
    "\n",
    "## Here we save the topics in a readable csv file\n",
    "\n",
    "numTopics = 20\n",
    "topics = {\"topic\":[],\"word\":[],\"weight\":[]}\n",
    "for topic in range(numTopics):\n",
    "    x = ldamodel.show_topic(topic,20)\n",
    "    for weight, word in x:\n",
    "        topics[\"topic\"].append(topic)\n",
    "        topics[\"word\"].append(word)\n",
    "        topics[\"weight\"].append(weight)\n",
    "topics = pandas.DataFrame(topics)\n",
    "\n",
    "topics.to_csv(\"topics20.csv\")\n",
    "\n",
    "# Here, we store the distribution of topics in every article\n",
    "\n",
    "topicDists = [ ldamodel[corpus[i]] for i in range(len(corpus)) ]\n",
    "\n",
    "# convert it into a dataframe\n",
    "topic_article_Dists = pandas.DataFrame(topicDists)\n",
    "\n",
    "# select only the probabilities for each column\n",
    "topic_article_Dists = pandas.concat([topic_article_Dists[x].str[1] for x in topic_article_Dists.columns], axis=1)\n",
    "\n",
    "# save the output as a csv file\n",
    "topic_article_Dists.to_csv(\"Article-Topic-Distri20.csv\")        \n",
    "           \n",
    "## Save the date in a csv file         \n",
    "Date = pandas.DataFrame(appended_data.date)   \n",
    "Date.to_csv(\"Date_20.csv\")     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Word2vec\n",
    "The below sets up the word2vec framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6994419, 9000230)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:/Users/rasmusa/Desktop/python/Chinese_Risk/data/output')\n",
    "\n",
    "## Libraries to download\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import csv\n",
    "\n",
    "#from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "## Tokenizing\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "## Reading the data\n",
    "import json\n",
    "#import nltk\n",
    "#import re\n",
    "import pandas\n",
    "\n",
    "\n",
    "## English Stopwords\n",
    "English_Stopwords = open(\"English_Stopwords.txt\").read()\n",
    "English_Stopwords1=English_Stopwords.split('\\n')\n",
    "\n",
    "\n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in doc_set:\n",
    "\n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove all tokens that are not alphabetic\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "\n",
    "    texts.append(words)\n",
    "\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    texts,\n",
    "    size=150,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=10)\n",
    "\n",
    "model.train(texts, total_examples=len(texts), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Words most similar to risk\n",
    "We can now explore the top 100 words that are most similar to risk and finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('risks', 0.6448798179626465),\n",
       " ('leverage', 0.487862765789032),\n",
       " ('problem', 0.43997374176979065),\n",
       " ('conditions', 0.4376317858695984),\n",
       " ('negative', 0.417447566986084),\n",
       " ('nature', 0.40873077511787415),\n",
       " ('unstable', 0.3954346776008606),\n",
       " ('payout', 0.3952161967754364),\n",
       " ('opaque', 0.3927227258682251),\n",
       " ('quality', 0.3884698152542114),\n",
       " ('standards', 0.3877885341644287),\n",
       " ('backdrop', 0.3865804672241211),\n",
       " ('stable', 0.378500372171402),\n",
       " ('distortion', 0.3751464784145355),\n",
       " ('hazard', 0.3748941123485565),\n",
       " ('defaults', 0.374076247215271),\n",
       " ('fairly', 0.36818063259124756),\n",
       " ('causes', 0.366767019033432),\n",
       " ('argument', 0.365559458732605),\n",
       " ('given', 0.3650939464569092),\n",
       " ('painful', 0.3640231192111969),\n",
       " ('probability', 0.3633217215538025),\n",
       " ('danger', 0.362758994102478),\n",
       " ('proponent', 0.3617668151855469),\n",
       " ('grind', 0.36068451404571533),\n",
       " ('transparency', 0.36030688881874084),\n",
       " ('problems', 0.3601911664009094),\n",
       " ('regulation', 0.35937705636024475),\n",
       " ('roules', 0.35761839151382446),\n",
       " ('deterioration', 0.3574985861778259),\n",
       " ('mismatch', 0.35611337423324585),\n",
       " ('sheets', 0.3525438904762268),\n",
       " ('environment', 0.349037230014801),\n",
       " ('vulnerabilities', 0.34606122970581055),\n",
       " ('potential', 0.34412842988967896),\n",
       " ('pain', 0.3438741862773895),\n",
       " ('levels', 0.3424549698829651),\n",
       " ('diversity', 0.34200501441955566),\n",
       " ('robust', 0.3410804271697998),\n",
       " ('likelihood', 0.3392864465713501),\n",
       " ('governance', 0.3385600745677948),\n",
       " ('jeopardize', 0.33768680691719055),\n",
       " ('guarantee', 0.33685171604156494),\n",
       " ('excessive', 0.33310019969940186),\n",
       " ('fiendishly', 0.3326813876628876),\n",
       " ('bad', 0.33226078748703003),\n",
       " ('blanket', 0.3314353823661804),\n",
       " ('highly', 0.328464150428772),\n",
       " ('volatility', 0.3283099830150604),\n",
       " ('impact', 0.326779305934906),\n",
       " ('healthy', 0.32673943042755127),\n",
       " ('adequate', 0.3252093195915222),\n",
       " ('threat', 0.32445651292800903),\n",
       " ('hazards', 0.3232632279396057),\n",
       " ('profile', 0.32188963890075684),\n",
       " ('sheet', 0.32081836462020874),\n",
       " ('gradually', 0.3203062415122986),\n",
       " ('shocks', 0.319854199886322),\n",
       " ('promise', 0.3195194602012634),\n",
       " ('situation', 0.31943804025650024),\n",
       " ('consequences', 0.3182409703731537),\n",
       " ('thus', 0.3174360692501068),\n",
       " ('risky', 0.31735944747924805),\n",
       " ('cause', 0.31705862283706665),\n",
       " ('sound', 0.3155277371406555),\n",
       " ('profiles', 0.3153226375579834),\n",
       " ('fast', 0.31474024057388306),\n",
       " ('bubbles', 0.3133949041366577),\n",
       " ('corporate', 0.31331706047058105),\n",
       " ('mizuho', 0.3126879036426544),\n",
       " ('spreads', 0.3124171495437622),\n",
       " ('function', 0.31207674741744995),\n",
       " ('contagion', 0.31203460693359375),\n",
       " ('possibility', 0.31150978803634644),\n",
       " ('increasing', 0.3111809492111206),\n",
       " ('sacrificing', 0.3109701871871948),\n",
       " ('deforestation', 0.3099862337112427),\n",
       " ('extremely', 0.30956974625587463),\n",
       " ('inclusiveness', 0.3093745708465576),\n",
       " ('serious', 0.3092636466026306),\n",
       " ('ratios', 0.3087998032569885),\n",
       " ('liquidity', 0.3084818720817566),\n",
       " ('unwinding', 0.30844032764434814),\n",
       " ('fitch', 0.3071383237838745),\n",
       " ('solvency', 0.3069702386856079),\n",
       " ('loads', 0.306640088558197),\n",
       " ('moment', 0.3054400086402893),\n",
       " ('view', 0.3033483028411865),\n",
       " ('profitability', 0.3027797341346741),\n",
       " ('adhere', 0.30148887634277344),\n",
       " ('compliance', 0.3014712631702423),\n",
       " ('returns', 0.30095863342285156),\n",
       " ('vigilant', 0.30031171441078186),\n",
       " ('moral', 0.2997651696205139),\n",
       " ('assessment', 0.29936379194259644),\n",
       " ('trend', 0.2979286313056946),\n",
       " ('repercussions', 0.2979270815849304),\n",
       " ('dangers', 0.2971450090408325),\n",
       " ('practice', 0.2960902452468872),\n",
       " ('means', 0.29551708698272705)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_risk = model.most_similar(['risk'], topn=100)\n",
    "result_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('financing', 0.4269069731235504),\n",
       " ('proposed', 0.38867759704589844),\n",
       " ('govern', 0.37845876812934875),\n",
       " ('jiwei', 0.37800031900405884),\n",
       " ('prime', 0.37565547227859497),\n",
       " ('banking', 0.3700164556503296),\n",
       " ('lending', 0.3570162057876587),\n",
       " ('commerce', 0.35553139448165894),\n",
       " ('securitiesfinance', 0.3537396490573883),\n",
       " ('tsipras', 0.35154497623443604),\n",
       " ('mckinsey', 0.34610962867736816),\n",
       " ('jointly', 0.34447425603866577),\n",
       " ('tighten', 0.3406780958175659),\n",
       " ('drafting', 0.33930468559265137),\n",
       " ('regulate', 0.33681434392929077),\n",
       " ('trustee', 0.32900261878967285),\n",
       " ('chiefly', 0.323551207780838),\n",
       " ('factual', 0.32240742444992065),\n",
       " ('nagano', 0.31778717041015625),\n",
       " ('broaden', 0.3177682161331177),\n",
       " ('jams', 0.31592032313346863),\n",
       " ('padoan', 0.31486770510673523),\n",
       " ('amplified', 0.3141745924949646),\n",
       " ('guidelines', 0.3136821985244751),\n",
       " ('poorest', 0.31070470809936523),\n",
       " ('benefitting', 0.3103598952293396),\n",
       " ('peer', 0.3101802468299866),\n",
       " ('designed', 0.3046668767929077),\n",
       " ('shinzo', 0.3007515072822571),\n",
       " ('g', 0.29869553446769714),\n",
       " ('calls', 0.29697099328041077),\n",
       " ('alexis', 0.2951952815055847),\n",
       " ('activities', 0.29451486468315125),\n",
       " ('levered', 0.2931523621082306),\n",
       " ('published', 0.2923687696456909),\n",
       " ('symbolism', 0.2910813093185425),\n",
       " ('instructions', 0.29081907868385315),\n",
       " ('condemnation', 0.2882130742073059),\n",
       " ('bifurcation', 0.2879433333873749),\n",
       " ('lou', 0.2877834737300873),\n",
       " ('unofficial', 0.28675973415374756),\n",
       " ('financial', 0.2864561080932617),\n",
       " ('kid', 0.2844136953353882),\n",
       " ('representatives', 0.28381457924842834),\n",
       " ('development', 0.28155258297920227),\n",
       " ('carlo', 0.28126096725463867),\n",
       " ('ministers', 0.28092071413993835),\n",
       " ('broadens', 0.2806839644908905),\n",
       " ('aviation', 0.28020352125167847),\n",
       " ('assessing', 0.2797966003417969),\n",
       " ('advises', 0.27917370200157166),\n",
       " ('component', 0.27571576833724976),\n",
       " ('ida', 0.275671124458313),\n",
       " ('setback', 0.2751697301864624),\n",
       " ('frieden', 0.27511659264564514),\n",
       " ('exploring', 0.2729523181915283),\n",
       " ('commitments', 0.27247896790504456),\n",
       " ('cairns', 0.27197742462158203),\n",
       " ('overseeing', 0.2710490822792053),\n",
       " ('approval', 0.27045413851737976),\n",
       " ('schauble', 0.26839926838874817),\n",
       " ('elevate', 0.26742708683013916),\n",
       " ('goaded', 0.2670286297798157),\n",
       " ('attended', 0.26655149459838867),\n",
       " ('adhered', 0.2655108869075775),\n",
       " ('corporation', 0.2649677097797394),\n",
       " ('minister', 0.2645440697669983),\n",
       " ('bottleneck', 0.2638665437698364),\n",
       " ('supervise', 0.26335591077804565),\n",
       " ('communiqué', 0.2628122568130493),\n",
       " ('brics', 0.26112309098243713),\n",
       " ('assortment', 0.26070618629455566),\n",
       " ('implements', 0.26011723279953003),\n",
       " ('trust', 0.25899919867515564),\n",
       " ('convened', 0.25812003016471863),\n",
       " ('collaborative', 0.25772303342819214),\n",
       " ('national', 0.25662142038345337),\n",
       " ('prohibiting', 0.2565908432006836),\n",
       " ('photovoltaic', 0.25533175468444824),\n",
       " ('abe', 0.2533045709133148),\n",
       " ('commission', 0.2521871328353882),\n",
       " ('htite', 0.2521723508834839),\n",
       " ('accumulating', 0.25215986371040344),\n",
       " ('cips', 0.25199347734451294),\n",
       " ('regulation', 0.2519134283065796),\n",
       " ('expressway', 0.2513008117675781),\n",
       " ('verified', 0.2505151927471161),\n",
       " ('transferred', 0.24951030313968658),\n",
       " ('comprehensive', 0.24943487346172333),\n",
       " ('pier', 0.24863769114017487),\n",
       " ('bndes', 0.24744091928005219),\n",
       " ('hotspots', 0.24712038040161133),\n",
       " ('lobbying', 0.24697136878967285),\n",
       " ('strategy', 0.2464369535446167),\n",
       " ('airport', 0.24622657895088196),\n",
       " ('tilted', 0.2461588978767395),\n",
       " ('nongovernmental', 0.24612949788570404),\n",
       " ('revising', 0.24609656631946564),\n",
       " ('registration', 0.2456725388765335),\n",
       " ('gegi', 0.24544841051101685)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_finance = model.most_similar(['finance'], topn=100)\n",
    "result_finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               risks\n",
       "1            leverage\n",
       "2             problem\n",
       "3          conditions\n",
       "4           standards\n",
       "5              nature\n",
       "6              opaque\n",
       "7               given\n",
       "8             painful\n",
       "9            backdrop\n",
       "10           unstable\n",
       "11          extremely\n",
       "12          technical\n",
       "13             stable\n",
       "14          situation\n",
       "15             danger\n",
       "16          vasudevan\n",
       "17           solvency\n",
       "18          proponent\n",
       "19         regulation\n",
       "20           defaults\n",
       "21         governance\n",
       "22            quality\n",
       "23          unwinding\n",
       "24      deterioration\n",
       "25             causes\n",
       "26              avoid\n",
       "27    vulnerabilities\n",
       "28         volatility\n",
       "29              risky\n",
       "           ...       \n",
       "70             roules\n",
       "71          deflation\n",
       "72             assess\n",
       "73         corporates\n",
       "74         structured\n",
       "75          exhibited\n",
       "76               pain\n",
       "77             mature\n",
       "78         assessment\n",
       "79        possibility\n",
       "80               seem\n",
       "81             shocks\n",
       "82              moral\n",
       "83         allocation\n",
       "84               case\n",
       "85            bubbles\n",
       "86             stress\n",
       "87             highly\n",
       "88             intact\n",
       "89           vigilant\n",
       "90           heighten\n",
       "91           positive\n",
       "92             threat\n",
       "93             burden\n",
       "94            hazards\n",
       "95         rainstorms\n",
       "96               liao\n",
       "97            wrinkle\n",
       "98           profiles\n",
       "99              sheet\n",
       "Name: 0, Length: 100, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
